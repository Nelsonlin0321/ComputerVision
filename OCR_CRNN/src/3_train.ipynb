{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "from dataset import Synth90kDataset, synth90k_collate_fn\n",
    "from model import CRNN\n",
    "from evaluate import evaluate\n",
    "from config import train_config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Fuctions\n",
    "\n",
    "### Comments\n",
    "\n",
    "Shape\n",
    "\n",
    "- images: (N, C, H, W) -> (32, 1, 32, 100)\n",
    "- targets：(X, ),one dimenstion ，32 batch labels\n",
    "- logits：(T, N, n_class) -> (24, 32, 37)\n",
    "- input_lengths: (N,) -> (32, ), one dimenstion A batch with 32 sample of(input character length)\n",
    "- target_lengths: (N, ) ->(32, ), one dimenstion A batch with 32 sample of(target character length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init signature: CTCLoss(blank:int=0, reduction:str='mean', zero_infinity:bool=False)\n",
    "Docstring:     \n",
    "The Connectionist Temporal Classification loss.\n",
    "\n",
    "Calculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the\n",
    "probability of possible alignments of input to target, producing a loss value which is differentiable\n",
    "with respect to each input node. The alignment of input to target is assumed to be \"many-to-one\", which\n",
    "limits the length of the target sequence such that it must be :math:`\\leq` the input length.\n",
    "\n",
    "- log_probs：shape为(T, N, C)的模型输出张量，其中，T表示CTCLoss的输入长度也即输出序列长度，N表示训练的batch size长度，C则表示包含有空白标签的所有要预测的字符集总长度，log_probs一般需要经过torch.nn.functional.log_softmax处理后再送入到CTCLoss中；\n",
    "\n",
    "- targets：shape为(N, S) 或(sum(target_lengths))的张量，其中第一种类型，N表示训练的batch size长度，S则为标签长度，第二种类型，则为所有标签长度之和，但是需要注意的是targets不能包含有空白标签；\n",
    "\n",
    "- input_lengths：shape为(N)的张量或元组，但每一个元素的长度必须等于T即输出序列长度，一般来说模型输出序列固定后则该张量或元组的元素值均相同；\n",
    "\n",
    "- target_lengths：shape为(N)的张量或元组，其每一个元素指示每个训练输入序列的标签长度，但标签长度是可以变化的；\n",
    "\n",
    "Args:\n",
    "    blank (int, optional): blank label. Default :math:`0`.\n",
    "    reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
    "        ``'mean'``: the output losses will be divided by the target lengths and\n",
    "        then the mean over the batch is taken. Default: ``'mean'``\n",
    "    zero_infinity (bool, optional):\n",
    "        Whether to zero infinite losses and the associated gradients.\n",
    "        Default: ``False``\n",
    "        Infinite losses mainly occur when the inputs are too short\n",
    "        to be aligned to the targets.\n",
    "\n",
    "Shape:\n",
    "    - Log_probs: Tensor of size :math:`(T, N, C)`,\n",
    "      where :math:`T = \\text{input length}`,\n",
    "      :math:`N = \\text{batch size}`, and\n",
    "      :math:`C = \\text{number of classes (including blank)}`.\n",
    "      The logarithmized probabilities of the outputs (e.g. obtained with\n",
    "      :func:`torch.nn.functional.log_softmax`).\n",
    "    - Targets: Tensor of size :math:`(N, S)` or\n",
    "      :math:`(\\operatorname{sum}(\\text{target\\_lengths}))`,\n",
    "      where :math:`N = \\text{batch size}` and\n",
    "      :math:`S = \\text{max target length, if shape is } (N, S)`.\n",
    "      It represent the target sequences. Each element in the target\n",
    "      sequence is a class index. And the target index cannot be blank (default=0).\n",
    "      In the :math:`(N, S)` form, targets are padded to the\n",
    "      length of the longest sequence, and stacked.\n",
    "      In the :math:`(\\operatorname{sum}(\\text{target\\_lengths}))` form,\n",
    "      the targets are assumed to be un-padded and\n",
    "      concatenated within 1 dimension.\n",
    "    - Input_lengths: Tuple or tensor of size :math:`(N)`,\n",
    "      where :math:`N = \\text{batch size}`. It represent the lengths of the\n",
    "      inputs (must each be :math:`\\leq T`). And the lengths are specified\n",
    "      for each sequence to achieve masking under the assumption that sequences\n",
    "      are padded to equal lengths.\n",
    "    - Target_lengths: Tuple or tensor of size :math:`(N)`,\n",
    "      where :math:`N = \\text{batch size}`. It represent lengths of the targets.\n",
    "      Lengths are specified for each sequence to achieve masking under the\n",
    "      assumption that sequences are padded to equal lengths. If target shape is\n",
    "      :math:`(N,S)`, target_lengths are effectively the stop index\n",
    "      :math:`s_n` for each target sequence, such that ``target_n = targets[n,0:s_n]`` for\n",
    "      each target in a batch. Lengths must each be :math:`\\leq S`\n",
    "      If the targets are given as a 1d tensor that is the concatenation of individual\n",
    "      targets, the target_lengths must add up to the total length of the tensor.\n",
    "    - Output: scalar. If :attr:`reduction` is ``'none'``, then\n",
    "      :math:`(N)`, where :math:`N = \\text{batch size}`.\n",
    "\n",
    "Examples::\n",
    "\n",
    "    >>> # Target are to be padded\n",
    "    >>> T = 50      # Input sequence length\n",
    "    >>> C = 20      # Number of classes (including blank)\n",
    "    >>> N = 16      # Batch size\n",
    "    >>> S = 30      # Target sequence length of longest target in batch (padding length)\n",
    "    >>> S_min = 10  # Minimum target length, for demonstration purposes\n",
    "    >>>\n",
    "    >>> # Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "    >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "    >>>\n",
    "    >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "    >>> target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "    >>>\n",
    "    >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "    >>> target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
    "    >>> ctc_loss = nn.CTCLoss()\n",
    "    >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "    >>> loss.backward()\n",
    "    >>>\n",
    "    >>>\n",
    "    >>> # Target are to be un-padded\n",
    "    >>> T = 50      # Input sequence length\n",
    "    >>> C = 20      # Number of classes (including blank)\n",
    "    >>> N = 16      # Batch size\n",
    "    >>>\n",
    "    >>> # Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "    >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "    >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "    >>>\n",
    "    >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "    >>> target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)\n",
    "    >>> target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)\n",
    "    >>> ctc_loss = nn.CTCLoss()\n",
    "    >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "    >>> loss.backward()\n",
    "\n",
    "Reference:\n",
    "    A. Graves et al.: Connectionist Temporal Classification:\n",
    "    Labelling Unsegmented Sequence Data with Recurrent Neural Networks:\n",
    "    https://www.cs.toronto.edu/~graves/icml_2006.pdf\n",
    "\n",
    "Note:\n",
    "    In order to use CuDNN, the following must be satisfied: :attr:`targets` must be\n",
    "    in concatenated format, all :attr:`input_lengths` must be `T`.  :math:`blank=0`,\n",
    "    :attr:`target_lengths` :math:`\\leq 256`, the integer arguments must be of\n",
    "    dtype :attr:`torch.int32`.\n",
    "\n",
    "    The regular implementation uses the (more common in PyTorch) `torch.long` dtype.\n",
    "\n",
    "\n",
    "Note:\n",
    "    In some circumstances when using the CUDA backend with CuDNN, this operator\n",
    "    may select a nondeterministic algorithm to increase performance. If this is\n",
    "    undesirable, you can try to make the operation deterministic (potentially at\n",
    "    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n",
    "    True``.\n",
    "    Please see the notes on :doc:`/notes/randomness` for background.\n",
    "Init docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
    "File:           d:\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py\n",
    "Type:           type\n",
    "Subclasses:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50      # Input sequence length\n",
    "C = 20      # Number of classes (including blank)\n",
    "N = 16      # Batch size\n",
    "S = 30      # Target sequence length of longest target in batch (padding length)\n",
    "S_min = 10  # Minimum target length, for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 16, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.7639, -2.6277, -2.6374, -4.4793, -2.2352, -4.4302, -4.1634, -4.2208,\n",
       "        -3.6696, -1.5673, -5.3828, -3.0010, -3.2726, -2.5471, -3.9482, -3.0687,\n",
       "        -1.9266, -4.3272, -3.9098, -3.7618], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[:,0,:][0] ## the first sample and the first time sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "target.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28, 17, 29, 27, 28, 21, 20, 17, 15, 16, 19, 13, 27, 14, 13, 18])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_loss = CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.1596, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Patermeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = config['epochs']\n",
    "train_batch_size = config['train_batch_size']\n",
    "eval_batch_size = config['eval_batch_size']\n",
    "lr = config['lr']\n",
    "show_interval = config['show_interval']\n",
    "valid_interval = config['valid_interval']\n",
    "save_interval = config['save_interval']\n",
    "cpu_workers = config['cpu_workers']\n",
    "reload_checkpoint = config['reload_checkpoint']\n",
    "valid_max_iter = config['valid_max_iter']\n",
    "\n",
    "img_width = config['img_width']\n",
    "img_height = config['img_height']\n",
    "data_dir = config['data_dir']\n",
    "\n",
    "num_class = len(Synth90kDataset.LABEL2CHAR) + 1\n",
    "\n",
    "cpu_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Synth90kDataset(root_dir=data_dir, mode='train',\n",
    "                                    img_height=img_height, img_width=img_width)\n",
    "valid_dataset = Synth90kDataset(root_dir=data_dir, mode='dev',\n",
    "                                img_height=img_height, img_width=img_width)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cpu_workers,\n",
    "    collate_fn=synth90k_collate_fn)\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=eval_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cpu_workers,\n",
    "    collate_fn=synth90k_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (pooling2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu4): ReLU(inplace=True)\n",
       "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu5): ReLU(inplace=True)\n",
       "    (pooling3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (relu6): ReLU(inplace=True)\n",
       "  )\n",
       "  (map_to_seq): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (rnn1): LSTM(64, 256, bidirectional=True)\n",
       "  (rnn2): LSTM(512, 256, bidirectional=True)\n",
       "  (dense): Linear(in_features=512, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn = CRNN(1, img_height, img_width, num_class,\n",
    "            map_to_seq_hidden=config['map_to_seq_hidden'],\n",
    "            rnn_hidden=config['rnn_hidden'],\n",
    "            leaky_relu=config['leaky_relu'])\n",
    "if reload_checkpoint:\n",
    "    crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))\n",
    "crnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTCLoss()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(crnn.parameters(), lr=lr)\n",
    "criterion = CTCLoss(reduction='sum')\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert save_interval % valid_interval == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing\n",
    "i = 0\n",
    "for train_data in train_loader:\n",
    "    sample_train_data = train_data\n",
    "    i+=1\n",
    "    if i==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = crnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets, target_lengths = [d.to(device) for d in sample_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = crnn(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 32, 37])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape # (T, N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.nn.functional.log_softmax(logits, dim=2) # softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.5903, -3.6474, -3.6094, -3.5912, -3.5892, -3.6407, -3.6404, -3.6426,\n",
       "        -3.5924, -3.5884, -3.5724, -3.6011, -3.6278, -3.6061, -3.5878, -3.5853,\n",
       "        -3.5867, -3.6093, -3.5839, -3.6416, -3.6299, -3.5777, -3.6182, -3.5736,\n",
       "        -3.6282, -3.6013, -3.6061, -3.6388, -3.6249, -3.5818, -3.6279, -3.6625,\n",
       "        -3.6213, -3.6277, -3.6130, -3.6108, -3.6363], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs[:,0,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = images.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths = torch.LongTensor([logits.size(0)] * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
       "        24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lengths = torch.flatten(target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  5, 10,  5, 14,  7,  8, 12, 11,  7, 11,  9,  5, 11,  7,  7, 13,  7,\n",
       "         7,  5,  9,  6, 10,  7,  7, 11,  9,  8, 10,  7,  9,  8],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(log_probs, targets, input_lengths, target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2139.9348, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = crnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(crnn, data, optimizer, criterion, device):\n",
    "    crnn.train()\n",
    "    images, targets, target_lengths = [d.to(device) for d in data]\n",
    "\n",
    "    logits = crnn(images)\n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
    "\n",
    "    batch_size = images.size(0)\n",
    "    input_lengths = torch.LongTensor([logits.size(0)] * batch_size)\n",
    "    target_lengths = torch.flatten(target_lengths)\n",
    "\n",
    "    loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "train_batch_loss[ 10 ]:  27.803953170776367\n",
      "train_batch_loss[ 20 ]:  24.912765502929688\n",
      "train_batch_loss[ 30 ]:  23.342370986938477\n",
      "train_batch_loss[ 40 ]:  27.656431198120117\n",
      "train_batch_loss[ 50 ]:  24.8463134765625\n",
      "train_loss:  27.45540482855296\n",
      "epoch: 2\n",
      "train_batch_loss[ 60 ]:  24.50200080871582\n",
      "train_batch_loss[ 70 ]:  26.64198875427246\n",
      "train_batch_loss[ 80 ]:  24.154861450195312\n",
      "train_batch_loss[ 90 ]:  27.972400665283203\n",
      "train_batch_loss[ 100 ]:  24.27780532836914\n",
      "train_batch_loss[ 110 ]:  26.269683837890625\n",
      "train_loss:  25.37368762473143\n",
      "epoch: 3\n",
      "train_batch_loss[ 120 ]:  24.99655532836914\n",
      "train_batch_loss[ 130 ]:  25.585840225219727\n",
      "train_batch_loss[ 140 ]:  26.731746673583984\n",
      "train_batch_loss[ 150 ]:  26.63530921936035\n",
      "train_batch_loss[ 160 ]:  25.008487701416016\n",
      "train_loss:  25.16807632062474\n",
      "epoch: 4\n",
      "train_batch_loss[ 170 ]:  25.0599422454834\n",
      "train_batch_loss[ 180 ]:  24.829959869384766\n",
      "train_batch_loss[ 190 ]:  24.508867263793945\n",
      "train_batch_loss[ 200 ]:  23.783641815185547\n",
      "train_batch_loss[ 210 ]:  25.230031967163086\n",
      "train_batch_loss[ 220 ]:  24.901662826538086\n",
      "train_loss:  25.06069849055862\n",
      "epoch: 5\n",
      "train_batch_loss[ 230 ]:  24.56756591796875\n",
      "train_batch_loss[ 240 ]:  24.323238372802734\n",
      "train_batch_loss[ 250 ]:  23.910858154296875\n",
      "train_batch_loss[ 260 ]:  23.745563507080078\n",
      "train_batch_loss[ 270 ]:  25.172679901123047\n",
      "train_batch_loss[ 280 ]:  26.466102337015087\n",
      "train_loss:  24.981720328930706\n",
      "epoch: 6\n",
      "train_batch_loss[ 290 ]:  23.035686492919922\n",
      "train_batch_loss[ 300 ]:  27.790325164794922\n",
      "train_batch_loss[ 310 ]:  26.176109313964844\n",
      "train_batch_loss[ 320 ]:  25.545066833496094\n",
      "train_batch_loss[ 330 ]:  26.506122589111328\n",
      "train_loss:  24.881101332142606\n",
      "epoch: 7\n",
      "train_batch_loss[ 340 ]:  24.502399444580078\n",
      "train_batch_loss[ 350 ]:  24.321874618530273\n",
      "train_batch_loss[ 360 ]:  25.018905639648438\n",
      "train_batch_loss[ 370 ]:  25.336490631103516\n",
      "train_batch_loss[ 380 ]:  24.050392150878906\n",
      "train_batch_loss[ 390 ]:  23.543869018554688\n",
      "train_loss:  24.786124590324118\n",
      "epoch: 8\n",
      "train_batch_loss[ 400 ]:  24.63034439086914\n",
      "train_batch_loss[ 410 ]:  24.344778060913086\n",
      "train_batch_loss[ 420 ]:  24.378238677978516\n",
      "train_batch_loss[ 430 ]:  23.617992401123047\n",
      "train_batch_loss[ 440 ]:  24.107345581054688\n",
      "train_loss:  24.762038323118276\n",
      "epoch: 9\n",
      "train_batch_loss[ 450 ]:  23.301267623901367\n",
      "train_batch_loss[ 460 ]:  26.108970642089844\n",
      "train_batch_loss[ 470 ]:  24.26250457763672\n",
      "train_batch_loss[ 480 ]:  24.745492935180664\n",
      "train_batch_loss[ 490 ]:  23.655981063842773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluate:   0%|                                                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batch_loss[ 500 ]:  25.051483154296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:15<00:00, 15.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_evaluation: loss=25.001851821836098, acc=0.0\n",
      "train_loss:  24.688604603272168\n",
      "epoch: 10\n",
      "train_batch_loss[ 510 ]:  29.2703857421875\n",
      "train_batch_loss[ 520 ]:  25.738025665283203\n",
      "train_batch_loss[ 530 ]:  23.810016632080078\n",
      "train_batch_loss[ 540 ]:  23.943490982055664\n",
      "train_batch_loss[ 550 ]:  25.516605377197266\n",
      "train_batch_loss[ 560 ]:  27.051362136314655\n",
      "train_loss:  24.622436114034553\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    print(f'epoch: {epoch}')\n",
    "    tot_train_loss = 0.\n",
    "    tot_train_count = 0\n",
    "    for train_data in train_loader:\n",
    "        loss = train_batch(crnn, train_data, optimizer, criterion, device)\n",
    "        train_size = train_data[0].size(0)\n",
    "\n",
    "        tot_train_loss += loss\n",
    "        tot_train_count += train_size\n",
    "        if i % show_interval == 0:\n",
    "            print('train_batch_loss[', i, ']: ', loss / train_size)\n",
    "\n",
    "        if i % valid_interval == 0:\n",
    "            evaluation = evaluate(crnn, valid_loader, criterion,\n",
    "                                  decode_method=config['decode_method'],\n",
    "                                  beam_size=config['beam_size'])\n",
    "            # only once evey elements of sequences is correct, this same can be deemed as correct.  \n",
    "            print('valid_evaluation: loss={loss}, acc={acc}'.format(**evaluation))\n",
    "\n",
    "        if i % save_interval == 0:\n",
    "            prefix = 'crnn'\n",
    "            loss = evaluation['loss']\n",
    "            save_model_path = os.path.join(config['checkpoints_dir'],\n",
    "                                           f'{prefix}_{i:06}_loss{loss}.pt')\n",
    "            torch.save(crnn.state_dict(), save_model_path)\n",
    "            print('save model at ', save_model_path)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print('train_loss: ', tot_train_loss / tot_train_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
